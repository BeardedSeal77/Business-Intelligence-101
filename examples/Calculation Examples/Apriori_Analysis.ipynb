{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori Algorithm Analysis\n",
    "## Minimum Support = 0.3\n",
    "\n",
    "This notebook analyzes transaction data to find frequent itemsets and generate association rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Transactions: 10\n",
      "Minimum Support: 0.3\n",
      "Minimum Count: 3.0\n",
      "\n",
      "Transactions:\n",
      "1. Bread, Milk, Eggs\n",
      "2. Bread, Butter, Cheese\n",
      "3. Milk, Eggs, Butter\n",
      "4. Bread, Milk, Butter\n",
      "5. Bread, Eggs, Apples\n",
      "6. Milk, Eggs, Cheese\n",
      "7. Bread, Milk, Eggs, Butter\n",
      "8. Milk, Butter, Bananas\n",
      "9. Bread, Eggs, Butter\n",
      "10. Milk, Eggs, Butter, Cheese\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "# Transaction data from the CSV\n",
    "transactions = [\n",
    "    ['Bread', 'Milk', 'Eggs'],\n",
    "    ['Bread', 'Butter', 'Cheese'],\n",
    "    ['Milk', 'Eggs', 'Butter'],\n",
    "    ['Bread', 'Milk', 'Butter'],\n",
    "    ['Bread', 'Eggs', 'Apples'],\n",
    "    ['Milk', 'Eggs', 'Cheese'],\n",
    "    ['Bread', 'Milk', 'Eggs', 'Butter'],\n",
    "    ['Milk', 'Butter', 'Bananas'],\n",
    "    ['Bread', 'Eggs', 'Butter'],\n",
    "    ['Milk', 'Eggs', 'Butter', 'Cheese']\n",
    "]\n",
    "\n",
    "# Abbreviations for display\n",
    "abbrev = {\n",
    "    'Bread': 'B',\n",
    "    'Milk': 'M',\n",
    "    'Eggs': 'E',\n",
    "    'Butter': 'Bu',\n",
    "    'Cheese': 'C',\n",
    "    'Apples': 'A',\n",
    "    'Bananas': 'Ba'\n",
    "}\n",
    "\n",
    "total_transactions = len(transactions)\n",
    "min_support = 0.3\n",
    "min_count = min_support * total_transactions\n",
    "\n",
    "print(f\"Total Transactions: {total_transactions}\")\n",
    "print(f\"Minimum Support: {min_support}\")\n",
    "print(f\"Minimum Count: {min_count}\")\n",
    "print(f\"\\nTransactions:\")\n",
    "for i, trans in enumerate(transactions, 1):\n",
    "    print(f\"{i}. {', '.join(trans)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find Frequent 1-Itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Support\n",
    "\n",
    "**Support** measures how frequently an itemset appears in the dataset.\n",
    "\n",
    "### Formula:\n",
    "```\n",
    "Support(X) = Count(X) / Total Transactions\n",
    "```\n",
    "\n",
    "### Examples with our data (10 transactions):\n",
    "\n",
    "**1-Itemset:**\n",
    "- If Milk appears in 7 transactions: Support(Milk) = 7/10 = 0.7\n",
    "\n",
    "**2-Itemset:**\n",
    "- If {Bread, Milk} appears in 3 transactions: Support(Bread, Milk) = 3/10 = 0.3\n",
    "\n",
    "**3-Itemset:**\n",
    "- If {Bread, Milk, Eggs} appears in 2 transactions: Support(Bread, Milk, Eggs) = 2/10 = 0.2\n",
    "\n",
    "### Minimum Support Threshold:\n",
    "- Minimum support = 0.3 means an itemset must appear in at least 3 transactions (0.3 x 10 = 3)\n",
    "- Any itemset with support < 0.3 is NOT frequent and is pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent 1-Itemsets:\n",
      "Item  Count  Support\n",
      "   M      7      0.7\n",
      "   E      7      0.7\n",
      "  Bu      7      0.7\n",
      "   B      6      0.6\n",
      "   C      3      0.3\n",
      "\n",
      "Total frequent 1-itemsets: 5\n"
     ]
    }
   ],
   "source": [
    "# Count 1-itemsets\n",
    "item_counts = Counter()\n",
    "for transaction in transactions:\n",
    "    for item in transaction:\n",
    "        item_counts[item] += 1\n",
    "\n",
    "# Filter by minimum support\n",
    "frequent_1_itemsets = {item: count for item, count in item_counts.items() if count >= min_count}\n",
    "\n",
    "# Create DataFrame for display\n",
    "df_1_itemsets = pd.DataFrame([\n",
    "    {'Item': abbrev[item], 'Count': count, 'Support': count/total_transactions}\n",
    "    for item, count in sorted(frequent_1_itemsets.items(), key=lambda x: x[1], reverse=True)\n",
    "])\n",
    "\n",
    "print(\"Frequent 1-Itemsets:\")\n",
    "print(df_1_itemsets.to_string(index=False))\n",
    "print(f\"\\nTotal frequent 1-itemsets: {len(frequent_1_itemsets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find Frequent 2-Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent 2-Itemsets (Minimum Support = 0.3):\n",
      "Itemset         Items  Count  Support\n",
      " {E, M}    Eggs, Milk      5      0.5\n",
      "{Bu, M}  Butter, Milk      5      0.5\n",
      " {B, E}   Bread, Eggs      4      0.4\n",
      "{B, Bu} Bread, Butter      4      0.4\n",
      "{Bu, E}  Butter, Eggs      4      0.4\n",
      " {B, M}   Bread, Milk      3      0.3\n",
      "\n",
      "Total frequent 2-itemsets: 6\n"
     ]
    }
   ],
   "source": [
    "# Count 2-itemsets (only from frequent 1-itemsets)\n",
    "pair_counts = Counter()\n",
    "frequent_items = set(frequent_1_itemsets.keys())\n",
    "\n",
    "for transaction in transactions:\n",
    "    # Only consider items that are frequent\n",
    "    frequent_in_trans = [item for item in transaction if item in frequent_items]\n",
    "    # Generate all 2-item combinations\n",
    "    for pair in combinations(sorted(frequent_in_trans), 2):\n",
    "        pair_counts[pair] += 1\n",
    "\n",
    "# Filter by minimum support\n",
    "frequent_2_itemsets = {pair: count for pair, count in pair_counts.items() if count >= min_count}\n",
    "\n",
    "# Create DataFrame for display\n",
    "df_2_itemsets = pd.DataFrame([\n",
    "    {\n",
    "        'Itemset': f\"{{{abbrev[pair[0]]}, {abbrev[pair[1]]}}}\",\n",
    "        'Items': f\"{pair[0]}, {pair[1]}\",\n",
    "        'Count': count,\n",
    "        'Support': round(count/total_transactions, 2)\n",
    "    }\n",
    "    for pair, count in sorted(frequent_2_itemsets.items(), key=lambda x: x[1], reverse=True)\n",
    "])\n",
    "\n",
    "print(\"\\nFrequent 2-Itemsets (Minimum Support = 0.3):\")\n",
    "print(df_2_itemsets.to_string(index=False))\n",
    "print(f\"\\nTotal frequent 2-itemsets: {len(frequent_2_itemsets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Find Frequent 3-Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent 3-Itemsets (Minimum Support = 0.3):\n",
      "   Itemset              Items  Count  Support\n",
      "{Bu, E, M} Butter, Eggs, Milk      3      0.3\n",
      "\n",
      "Total frequent 3-itemsets: 1\n"
     ]
    }
   ],
   "source": [
    "# Count 3-itemsets (only from frequent 2-itemsets)\n",
    "triple_counts = Counter()\n",
    "\n",
    "for transaction in transactions:\n",
    "    # Only consider items that are frequent\n",
    "    frequent_in_trans = [item for item in transaction if item in frequent_items]\n",
    "    # Generate all 3-item combinations\n",
    "    for triple in combinations(sorted(frequent_in_trans), 3):\n",
    "        # Check if all 2-item subsets are frequent (Apriori property)\n",
    "        subsets_frequent = all(\n",
    "            tuple(sorted(pair)) in frequent_2_itemsets\n",
    "            for pair in combinations(triple, 2)\n",
    "        )\n",
    "        if subsets_frequent:\n",
    "            triple_counts[triple] += 1\n",
    "\n",
    "# Filter by minimum support\n",
    "frequent_3_itemsets = {triple: count for triple, count in triple_counts.items() if count >= min_count}\n",
    "\n",
    "# Create DataFrame for display\n",
    "df_3_itemsets = pd.DataFrame([\n",
    "    {\n",
    "        'Itemset': f\"{{{abbrev[triple[0]]}, {abbrev[triple[1]]}, {abbrev[triple[2]]}}}\",\n",
    "        'Items': f\"{triple[0]}, {triple[1]}, {triple[2]}\",\n",
    "        'Count': count,\n",
    "        'Support': round(count/total_transactions, 2)\n",
    "    }\n",
    "    for triple, count in sorted(frequent_3_itemsets.items(), key=lambda x: x[1], reverse=True)\n",
    "])\n",
    "\n",
    "print(\"\\nFrequent 3-Itemsets (Minimum Support = 0.3):\")\n",
    "if len(df_3_itemsets) > 0:\n",
    "    print(df_3_itemsets.to_string(index=False))\n",
    "else:\n",
    "    print(\"No frequent 3-itemsets found with minimum support of 0.3\")\n",
    "print(f\"\\nTotal frequent 3-itemsets: {len(frequent_3_itemsets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Association Rules from 2-Itemsets\n",
    "\n",
    "### Understanding Confidence\n",
    "\n",
    "**Confidence** measures how often items in the consequent appear in transactions that contain the antecedent.\n",
    "\n",
    "### Formula:\n",
    "```\n",
    "Confidence(A -> B) = Support(A, B) / Support(A)\n",
    "                   = Count(A and B together) / Count(A)\n",
    "```\n",
    "\n",
    "This tells us: \"If a customer buys A, what is the probability they also buy B?\"\n",
    "\n",
    "### Example Calculation:\n",
    "\n",
    "Consider the rule **Bread -> Milk**:\n",
    "- Count of {Bread, Milk} together = 3 transactions\n",
    "- Count of Bread alone = 6 transactions\n",
    "- Confidence = 3/6 = 0.50 = **50%**\n",
    "\n",
    "**Interpretation:** When customers buy Bread, they also buy Milk 50% of the time.\n",
    "\n",
    "### Why Generate Both Directions?\n",
    "\n",
    "For itemset {A, B}, we generate TWO rules:\n",
    "1. **A -> B**: Confidence = Count(A,B) / Count(A)\n",
    "2. **B -> A**: Confidence = Count(A,B) / Count(B)\n",
    "\n",
    "These usually have DIFFERENT confidence values because:\n",
    "- A might be common (appears often) -> lower confidence for A -> B\n",
    "- B might be rare (appears less) -> higher confidence for B -> A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules from 2-Itemsets:\n",
      "   Rule  Support  Confidence Calculation\n",
      " E -> M      0.5        0.71  5/7 = 0.71\n",
      " M -> E      0.5        0.71  5/7 = 0.71\n",
      "Bu -> M      0.5        0.71  5/7 = 0.71\n",
      "M -> Bu      0.5        0.71  5/7 = 0.71\n",
      " B -> E      0.4        0.67  4/6 = 0.67\n",
      "B -> Bu      0.4        0.67  4/6 = 0.67\n",
      " E -> B      0.4        0.57  4/7 = 0.57\n",
      "Bu -> B      0.4        0.57  4/7 = 0.57\n",
      "Bu -> E      0.4        0.57  4/7 = 0.57\n",
      "E -> Bu      0.4        0.57  4/7 = 0.57\n",
      " B -> M      0.3        0.50  3/6 = 0.50\n",
      " M -> B      0.3        0.43  3/7 = 0.43\n"
     ]
    }
   ],
   "source": [
    "rules_2 = []\n",
    "\n",
    "for pair, pair_count in frequent_2_itemsets.items():\n",
    "    item1, item2 = pair\n",
    "    support_pair = pair_count / total_transactions\n",
    "    \n",
    "    # Rule: item1 -> item2\n",
    "    support_item1 = frequent_1_itemsets[item1] / total_transactions\n",
    "    confidence_1_to_2 = pair_count / frequent_1_itemsets[item1]\n",
    "    \n",
    "    rules_2.append({\n",
    "        'Rule': f\"{abbrev[item1]} -> {abbrev[item2]}\",\n",
    "        'Full Rule': f\"{item1} -> {item2}\",\n",
    "        'Support': round(support_pair, 2),\n",
    "        'Confidence': round(confidence_1_to_2, 2),\n",
    "        'Calculation': f\"{pair_count}/{frequent_1_itemsets[item1]} = {confidence_1_to_2:.2f}\"\n",
    "    })\n",
    "    \n",
    "    # Rule: item2 -> item1\n",
    "    support_item2 = frequent_1_itemsets[item2] / total_transactions\n",
    "    confidence_2_to_1 = pair_count / frequent_1_itemsets[item2]\n",
    "    \n",
    "    rules_2.append({\n",
    "        'Rule': f\"{abbrev[item2]} -> {abbrev[item1]}\",\n",
    "        'Full Rule': f\"{item2} -> {item1}\",\n",
    "        'Support': round(support_pair, 2),\n",
    "        'Confidence': round(confidence_2_to_1, 2),\n",
    "        'Calculation': f\"{pair_count}/{frequent_1_itemsets[item2]} = {confidence_2_to_1:.2f}\"\n",
    "    })\n",
    "\n",
    "df_rules_2 = pd.DataFrame(rules_2)\n",
    "df_rules_2 = df_rules_2.sort_values('Confidence', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nAssociation Rules from 2-Itemsets:\")\n",
    "print(df_rules_2[['Rule', 'Support', 'Confidence', 'Calculation']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Association Rules from 3-Itemsets\n",
    "\n",
    "### Understanding 3-Itemset Rules\n",
    "\n",
    "From a 3-itemset {A, B, C}, we can generate **multiple types** of association rules:\n",
    "\n",
    "### Type 1: Two Items -> One Item\n",
    "Examples: {A, B} -> C, {A, C} -> B, {B, C} -> A\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "Confidence({A, B} -> C) = Support(A, B, C) / Support(A, B)\n",
    "                        = Count(A, B, C together) / Count(A, B together)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "- Rule: **{Butter, Eggs} -> Milk**\n",
    "- Count of {Butter, Eggs, Milk} together = 3 transactions\n",
    "- Count of {Butter, Eggs} together = 4 transactions\n",
    "- Confidence = 3/4 = 0.75 = **75%**\n",
    "- **Interpretation:** When customers buy both Butter AND Eggs, they also buy Milk 75% of the time.\n",
    "\n",
    "### Type 2: One Item -> Two Items\n",
    "Examples: A -> {B, C}, B -> {A, C}, C -> {A, B}\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "Confidence(A -> {B, C}) = Support(A, B, C) / Support(A)\n",
    "                        = Count(A, B, C together) / Count(A)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "- Rule: **Butter -> {Eggs, Milk}**\n",
    "- Count of {Butter, Eggs, Milk} together = 3 transactions\n",
    "- Count of Butter = 7 transactions\n",
    "- Confidence = 3/7 = 0.43 = **43%**\n",
    "- **Interpretation:** When customers buy Butter, they also buy BOTH Eggs AND Milk 43% of the time.\n",
    "\n",
    "### Key Insight:\n",
    "Type 1 rules ({A, B} -> C) typically have **higher confidence** than Type 2 rules (A -> {B, C}) because:\n",
    "- Type 1: More specific antecedent (two items) = fewer transactions = higher ratio\n",
    "- Type 2: General antecedent (one item) = more transactions = lower ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules from 3-Itemsets:\n",
      "        Rule  Support  Confidence Calculation\n",
      "{Bu, E} -> M      0.3        0.75  3/4 = 0.75\n",
      "{E, M} -> Bu      0.3        0.60  3/5 = 0.60\n",
      "{Bu, M} -> E      0.3        0.60  3/5 = 0.60\n",
      "Bu -> {E, M}      0.3        0.43  3/7 = 0.43\n",
      "E -> {Bu, M}      0.3        0.43  3/7 = 0.43\n",
      "M -> {Bu, E}      0.3        0.43  3/7 = 0.43\n"
     ]
    }
   ],
   "source": [
    "rules_3 = []\n",
    "\n",
    "for triple, triple_count in frequent_3_itemsets.items():\n",
    "    support_triple = triple_count / total_transactions\n",
    "    \n",
    "    # Generate all possible rules from this 3-itemset\n",
    "    for i in range(len(triple)):\n",
    "        # Single item consequent rules (e.g., {A, B} -> C)\n",
    "        consequent = triple[i]\n",
    "        antecedent = tuple(item for j, item in enumerate(triple) if j != i)\n",
    "        \n",
    "        # Get support of antecedent\n",
    "        antecedent_sorted = tuple(sorted(antecedent))\n",
    "        if antecedent_sorted in frequent_2_itemsets:\n",
    "            antecedent_count = frequent_2_itemsets[antecedent_sorted]\n",
    "            confidence = triple_count / antecedent_count\n",
    "            \n",
    "            ant_str = ', '.join([abbrev[item] for item in antecedent])\n",
    "            cons_str = abbrev[consequent]\n",
    "            \n",
    "            rules_3.append({\n",
    "                'Rule': f\"{{{ant_str}}} -> {cons_str}\",\n",
    "                'Full Rule': f\"{{{', '.join(antecedent)}}} -> {consequent}\",\n",
    "                'Support': round(support_triple, 2),\n",
    "                'Confidence': round(confidence, 2),\n",
    "                'Calculation': f\"{triple_count}/{antecedent_count} = {confidence:.2f}\"\n",
    "            })\n",
    "    \n",
    "    # Two item consequent rules (e.g., A -> {B, C})\n",
    "    for i in range(len(triple)):\n",
    "        antecedent = triple[i]\n",
    "        consequent = tuple(item for j, item in enumerate(triple) if j != i)\n",
    "        \n",
    "        # Get support of antecedent (single item)\n",
    "        if antecedent in frequent_1_itemsets:\n",
    "            antecedent_count = frequent_1_itemsets[antecedent]\n",
    "            confidence = triple_count / antecedent_count\n",
    "            \n",
    "            ant_str = abbrev[antecedent]\n",
    "            cons_str = ', '.join([abbrev[item] for item in consequent])\n",
    "            \n",
    "            rules_3.append({\n",
    "                'Rule': f\"{ant_str} -> {{{cons_str}}}\",\n",
    "                'Full Rule': f\"{antecedent} -> {{{', '.join(consequent)}}}\",\n",
    "                'Support': round(support_triple, 2),\n",
    "                'Confidence': round(confidence, 2),\n",
    "                'Calculation': f\"{triple_count}/{antecedent_count} = {confidence:.2f}\"\n",
    "            })\n",
    "\n",
    "if len(rules_3) > 0:\n",
    "    df_rules_3 = pd.DataFrame(rules_3)\n",
    "    df_rules_3 = df_rules_3.sort_values('Confidence', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nAssociation Rules from 3-Itemsets:\")\n",
    "    print(df_rules_3[['Rule', 'Support', 'Confidence', 'Calculation']].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo association rules from 3-itemsets (no frequent 3-itemsets found)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Contingency Table Analysis\n",
    "\n",
    "### Understanding Contingency Tables\n",
    "\n",
    "A **2x2 contingency table** helps us analyze the relationship between an antecedent and consequent in association rules.\n",
    "\n",
    "We'll analyze the rule: **{Milk, Eggs} -> Butter**\n",
    "\n",
    "The table shows four scenarios:\n",
    "- **Has both** antecedent AND consequent\n",
    "- **Has antecedent** but NOT consequent\n",
    "- **Does NOT have antecedent** but HAS consequent\n",
    "- **Has neither** antecedent NOR consequent\n",
    "\n",
    "### Key Metrics:\n",
    "\n",
    "**1. Support:**\n",
    "```\n",
    "Support({M, E} -> Bu) = Count({M, E, Bu}) / Total Transactions\n",
    "```\n",
    "\n",
    "**2. Confidence:**\n",
    "```\n",
    "Confidence({M, E} -> Bu) = Count({M, E, Bu}) / Count({M, E})\n",
    "```\n",
    "\n",
    "**3. Lift:**\n",
    "```\n",
    "Lift({M, E} -> Bu) = Confidence({M, E} -> Bu) / Support(Bu)\n",
    "                    = [Count({M, E, Bu}) / Count({M, E})] / [Count(Bu) / Total]\n",
    "```\n",
    "\n",
    "**Lift Interpretation:**\n",
    "- **Lift > 1**: Positive correlation (antecedent increases likelihood of consequent)\n",
    "- **Lift = 1**: No correlation (independent)\n",
    "- **Lift < 1**: Negative correlation (antecedent decreases likelihood of consequent)\n",
    "\n",
    "### Observed vs Expected:\n",
    "\n",
    "**Observed values:** Actual counts from the data\n",
    "\n",
    "**Expected values:** What we would expect if items were independent (no association)\n",
    "```\n",
    "Expected = (Row Total Ã— Column Total) / Grand Total\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONTINGENCY TABLE ANALYSIS: {Milk, Eggs} -> Butter\n",
      "================================================================================\n",
      "\n",
      "1. OBSERVED CONTINGENCY TABLE:\n",
      "------------------------------------------------------------\n",
      "                        Has Butter    No Butter    Row Total\n",
      "Has {Milk, Eggs}            3             2             5   \n",
      "No {Milk, Eggs}             4             1             5   \n",
      "Column Total              7             3             10  \n",
      "\n",
      "2. EXPECTED CONTINGENCY TABLE (if independent):\n",
      "------------------------------------------------------------\n",
      "                        Has Butter    No Butter    Row Total\n",
      "Has {Milk, Eggs}           3.5          1.5           5   \n",
      "No {Milk, Eggs}            3.5          1.5           5   \n",
      "Column Total              7             3             10  \n",
      "\n",
      "3. RULE METRICS: {{Milk, Eggs}} -> Butter\n",
      "------------------------------------------------------------\n",
      "Support({M, E})        = 5/10 = 0.50\n",
      "Support(Bu)            = 7/10 = 0.70\n",
      "Support({M, E, Bu})    = 3/10 = 0.30\n",
      "Confidence({M,E}->Bu) = 3/5 = 0.60\n",
      "Lift({M,E}->Bu)       = 0.60/0.70 = 0.86\n",
      "\n",
      "4. INTERPRETATION:\n",
      "------------------------------------------------------------\n",
      "Lift = 0.86 < 1\n",
      "NEGATIVE CORRELATION: Buying {{Milk, Eggs}} DECREASES the likelihood of buying Butter\n",
      "\n",
      "5. OBSERVED vs EXPECTED:\n",
      "------------------------------------------------------------\n",
      "Observed {M,E} with Bu:  3\n",
      "Expected {M,E} with Bu:  3.5\n",
      "Observed < Expected: There IS a negative association!\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Construct 2x2 Contingency Table for {Milk, Eggs} -> Butter\n",
    "print(\"=\"*80)\n",
    "print(\"CONTINGENCY TABLE ANALYSIS: {Milk, Eggs} -> Butter\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count the four scenarios\n",
    "has_ME_and_Bu = 0  # Has {Milk, Eggs} AND Butter\n",
    "has_ME_not_Bu = 0  # Has {Milk, Eggs} but NOT Butter\n",
    "not_ME_has_Bu = 0  # Does NOT have {Milk, Eggs} but HAS Butter\n",
    "not_ME_not_Bu = 0  # Does NOT have {Milk, Eggs} AND does NOT have Butter\n",
    "\n",
    "for transaction in transactions:\n",
    "    has_milk = 'Milk' in transaction\n",
    "    has_eggs = 'Eggs' in transaction\n",
    "    has_butter = 'Butter' in transaction\n",
    "    \n",
    "    has_ME = has_milk and has_eggs\n",
    "    \n",
    "    if has_ME and has_butter:\n",
    "        has_ME_and_Bu += 1\n",
    "    elif has_ME and not has_butter:\n",
    "        has_ME_not_Bu += 1\n",
    "    elif not has_ME and has_butter:\n",
    "        not_ME_has_Bu += 1\n",
    "    else:\n",
    "        not_ME_not_Bu += 1\n",
    "\n",
    "# Calculate totals\n",
    "total_has_ME = has_ME_and_Bu + has_ME_not_Bu\n",
    "total_not_ME = not_ME_has_Bu + not_ME_not_Bu\n",
    "total_has_Bu = has_ME_and_Bu + not_ME_has_Bu\n",
    "total_not_Bu = has_ME_not_Bu + not_ME_not_Bu\n",
    "\n",
    "print(\"\\n1. OBSERVED CONTINGENCY TABLE:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"                        Has Butter    No Butter    Row Total\")\n",
    "print(f\"Has {{Milk, Eggs}}          {has_ME_and_Bu:^6}        {has_ME_not_Bu:^6}        {total_has_ME:^6}\")\n",
    "print(f\"No {{Milk, Eggs}}           {not_ME_has_Bu:^6}        {not_ME_not_Bu:^6}        {total_not_ME:^6}\")\n",
    "print(f\"Column Total            {total_has_Bu:^6}        {total_not_Bu:^6}        {total_transactions:^6}\")\n",
    "\n",
    "# Calculate expected values\n",
    "expected_ME_Bu = (total_has_ME * total_has_Bu) / total_transactions\n",
    "expected_ME_notBu = (total_has_ME * total_not_Bu) / total_transactions\n",
    "expected_notME_Bu = (total_not_ME * total_has_Bu) / total_transactions\n",
    "expected_notME_notBu = (total_not_ME * total_not_Bu) / total_transactions\n",
    "\n",
    "print(\"\\n2. EXPECTED CONTINGENCY TABLE (if independent):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"                        Has Butter    No Butter    Row Total\")\n",
    "print(f\"Has {{Milk, Eggs}}         {expected_ME_Bu:^7.1f}      {expected_ME_notBu:^7.1f}       {total_has_ME:^6}\")\n",
    "print(f\"No {{Milk, Eggs}}          {expected_notME_Bu:^7.1f}      {expected_notME_notBu:^7.1f}       {total_not_ME:^6}\")\n",
    "print(f\"Column Total            {total_has_Bu:^6}        {total_not_Bu:^6}        {total_transactions:^6}\")\n",
    "\n",
    "# Calculate metrics\n",
    "support_ME = total_has_ME / total_transactions\n",
    "support_Bu = total_has_Bu / total_transactions\n",
    "support_ME_Bu = has_ME_and_Bu / total_transactions\n",
    "confidence_ME_Bu = has_ME_and_Bu / total_has_ME if total_has_ME > 0 else 0\n",
    "lift_ME_Bu = confidence_ME_Bu / support_Bu if support_Bu > 0 else 0\n",
    "\n",
    "print(\"\\n3. RULE METRICS: {{Milk, Eggs}} -> Butter\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Support({{M, E}})        = {total_has_ME}/{total_transactions} = {support_ME:.2f}\")\n",
    "print(f\"Support(Bu)            = {total_has_Bu}/{total_transactions} = {support_Bu:.2f}\")\n",
    "print(f\"Support({{M, E, Bu}})    = {has_ME_and_Bu}/{total_transactions} = {support_ME_Bu:.2f}\")\n",
    "print(f\"Confidence({{M,E}}->Bu) = {has_ME_and_Bu}/{total_has_ME} = {confidence_ME_Bu:.2f}\")\n",
    "print(f\"Lift({{M,E}}->Bu)       = {confidence_ME_Bu:.2f}/{support_Bu:.2f} = {lift_ME_Bu:.2f}\")\n",
    "\n",
    "print(\"\\n4. INTERPRETATION:\")\n",
    "print(\"-\" * 60)\n",
    "if lift_ME_Bu > 1:\n",
    "    print(f\"Lift = {lift_ME_Bu:.2f} > 1\")\n",
    "    print(\"POSITIVE CORRELATION: Buying {{Milk, Eggs}} INCREASES the likelihood of buying Butter\")\n",
    "    print(f\"Customers who buy {{Milk, Eggs}} are {lift_ME_Bu:.2f}x more likely to buy Butter\")\n",
    "elif lift_ME_Bu < 1:\n",
    "    print(f\"Lift = {lift_ME_Bu:.2f} < 1\")\n",
    "    print(\"NEGATIVE CORRELATION: Buying {{Milk, Eggs}} DECREASES the likelihood of buying Butter\")\n",
    "else:\n",
    "    print(f\"Lift = {lift_ME_Bu:.2f} = 1\")\n",
    "    print(\"NO CORRELATION: {{Milk, Eggs}} and Butter are independent\")\n",
    "\n",
    "print(\"\\n5. OBSERVED vs EXPECTED:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Observed {{M,E}} with Bu:  {has_ME_and_Bu}\")\n",
    "print(f\"Expected {{M,E}} with Bu:  {expected_ME_Bu:.1f}\")\n",
    "if has_ME_and_Bu > expected_ME_Bu:\n",
    "    print(f\"Observed > Expected: There IS a positive association!\")\n",
    "elif has_ME_and_Bu < expected_ME_Bu:\n",
    "    print(f\"Observed < Expected: There IS a negative association!\")\n",
    "else:\n",
    "    print(f\"Observed = Expected: Items appear to be independent\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Answer to Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUMMARY FOR ASSIGNMENT\n",
      "================================================================================\n",
      "\n",
      "Minimum Support: 0.3 (count >= 3.0)\n",
      "\n",
      "\n",
      "1. FREQUENT 2-ITEMSETS:\n",
      "------------------------------------------------------------\n",
      "Itemset  Count  Support\n",
      " {E, M}      5      0.5\n",
      "{Bu, M}      5      0.5\n",
      " {B, E}      4      0.4\n",
      "{B, Bu}      4      0.4\n",
      "{Bu, E}      4      0.4\n",
      " {B, M}      3      0.3\n",
      "\n",
      "\n",
      "2. FREQUENT 3-ITEMSETS:\n",
      "------------------------------------------------------------\n",
      "   Itemset  Count  Support\n",
      "{Bu, E, M}      3      0.3\n",
      "\n",
      "\n",
      "3. ASSOCIATION RULES WITH CONFIDENCE:\n",
      "------------------------------------------------------------\n",
      "\n",
      "From 2-Itemsets:\n",
      "   Rule  Confidence\n",
      " E -> M        0.71\n",
      " M -> E        0.71\n",
      "Bu -> M        0.71\n",
      "M -> Bu        0.71\n",
      " B -> E        0.67\n",
      "B -> Bu        0.67\n",
      " E -> B        0.57\n",
      "Bu -> B        0.57\n",
      "Bu -> E        0.57\n",
      "E -> Bu        0.57\n",
      " B -> M        0.50\n",
      " M -> B        0.43\n",
      "\n",
      "From 3-Itemsets:\n",
      "        Rule  Confidence\n",
      "{Bu, E} -> M        0.75\n",
      "{E, M} -> Bu        0.60\n",
      "{Bu, M} -> E        0.60\n",
      "Bu -> {E, M}        0.43\n",
      "E -> {Bu, M}        0.43\n",
      "M -> {Bu, E}        0.43\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY FOR ASSIGNMENT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nMinimum Support: {min_support} (count >= {min_count})\\n\")\n",
    "\n",
    "print(\"\\n1. FREQUENT 2-ITEMSETS:\")\n",
    "print(\"-\" * 60)\n",
    "print(df_2_itemsets[['Itemset', 'Count', 'Support']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n2. FREQUENT 3-ITEMSETS:\")\n",
    "print(\"-\" * 60)\n",
    "if len(frequent_3_itemsets) > 0:\n",
    "    print(df_3_itemsets[['Itemset', 'Count', 'Support']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No frequent 3-itemsets with support >= 0.3\")\n",
    "\n",
    "print(\"\\n\\n3. ASSOCIATION RULES WITH CONFIDENCE:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nFrom 2-Itemsets:\")\n",
    "print(df_rules_2[['Rule', 'Confidence']].to_string(index=False))\n",
    "\n",
    "if len(rules_3) > 0:\n",
    "    print(\"\\nFrom 3-Itemsets:\")\n",
    "    print(df_rules_3[['Rule', 'Confidence']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
